+++
title = "Pre ACL Event - Accepted Paper Discussion"
image = "/images/ev_acl25/theme_photo.png"
summary = "Speaker: Dr. Michael A. Hedderich, Zhijing Jin (PhD) and Lukas Edman | Jul 22, 2025 19:00-20:00"
url = "/events/acl-25-acc-paper-disc"
date = "2025-07-22"
+++


### Save the Date!
July 22th, 2025 19:00-20:00 -- [Munich🥨NLP Discord Server](https://discord.gg/qEcmhgGu43?event=1383134714818330826).



### About this Event

The Pre ACL Event is dedicated to presenting and discussing pioneering research in Natural Language Processing (NLP) in preparation for the main Association for Computational Linguistics (ACL) conference. Here's a summary of what the event is all about:

**Objective**: The primary goal of this event is to highlight top research papers that have been accepted at ACL. It offers a stage for researchers to display their work and participate in conversations about the latest progress in the field of NLP.

**Moderator**: [Daryna Dementieva](https://dardem.github.io/) will moderate the session, guiding the presentations and discussions throughout the event.

**Format**: The event is structured around presentations of research papers, followed by interactive discussions. The topics covered range from generative AI models and content moderation to understanding language models at a character level.

**Audience**: The event is aimed at researchers, practitioners, and enthusiasts in the field of NLP and AI. It is particularly appealing to those interested in the latest research and developments in these areas.
Papers discussed:

- **What's the Difference? Supporting Users in Identifying the Effects of Prompt and Model Changes Through Token Patterns**
  Michael A. Hedderich, Anyi Wang, Raoyuan Zhao, Florian Eichin, Jonas Fischer, Barbara Plank
  [Arxiv](https://arxiv.org/abs/2504.15815)
- **Revealing Hidden Mechanisms of Cross-Country Content Moderation with Natural Language Processing**
  Neemesh Yadav, Jiarui Liu, Francesco Ortu, Roya Ensafi, Zhijing Jin, Rada Mihalcea
  [Arxiv](https://arxiv.org/abs/2503.05280)
- **The Reasoning-Memorization Interplay in Language Models Is Mediated by a Single Direction**
  Yihuai Hong, Dian Zhou, Meng Cao, Lei Yu, Zhijing Jin
  [Arxiv](https://arxiv.org/abs/2503.23084)
- **EXECUTE: A Multilingual Benchmark for LLM Token Understanding**
  Lukas Edman, Helmut Schmid, Alexander Fraser
  [Arxiv](https://arxiv.org/abs/2505.17784)
- **Extending Context Window of Large Language Models via Positional Interpolation**
  Shouyuan Chen, Sherman Wong, Liangjian Chen, Yuandong Tian
  [Arxiv](https://arxiv.org/abs/2306.15595)



### Speakers

![Michael A. Hedderich ><](https://michael-hedderich.de/assets/img/IMG_5220_cut-out_circle_low-qual-1400.webp)

[**Dr. Michael A. Hedderich:**](https://michael-hedderich.de/) Focuses on research related to human-centric AI and NLP, with a particular emphasis on understanding and managing generative AI models and assisting users in these areas.


![Zhijing Jin ><](/images/ev_acl25/zhijing.jpg)

[**Dr. Zhijing Jin:**](https://zhijing-jin.com/home/) Her work revolves around causal inference in NLP and the safety of AI systems. Her presentations include topics such as content moderation on social media and the dynamics between reasoning and memorization in language models.


![Lukas Edman ><](https://avatars.githubusercontent.com/u/5771164?v=4)

[**Dr. Lukas Edman:**](https://leukas.github.io/) Specializes in character-level NLP and pretraining for languages with limited resources. His recent work involves benchmarking understanding of tokens by large language models (LLMs) and addressing positional biases in these models.